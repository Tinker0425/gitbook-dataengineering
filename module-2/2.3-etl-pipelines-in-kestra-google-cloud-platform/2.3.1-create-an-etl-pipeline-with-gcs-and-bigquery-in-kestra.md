---
description: Last updated 1/22/25
---

# 2.3.1 - Create an ETL Pipeline with GCS and BigQuery in Kestra

Youtube Video | \~20 min

{% embed url="https://youtu.be/nKqjjLJ7YXs" %}
[https://youtu.be/nKqjjLJ7YXs](https://youtu.be/nKqjjLJ7YXs)
{% endembed %}





Now that you've learned how to build ETL pipelines locally using Postgres, we are ready to move to the cloud. In this section, we'll load the same Yellow and Green Taxi data to Google Cloud Platform (GCP) using:

1. Google Cloud Storage (GCS) as a data lake
2. BigQuery as a data warehouse.



Add in 04 yaml to editor

Go to GCP and use a new space

IAM to create service account and add permisions. Once your account is created, click on it, and hit the 'Keys' tab. We will create a json key to add directly into our flow yaml (could also add it to the UI side on Kestra.

I changed my project ID

And I changed my locaation using

{% embed url="https://cloud.google.com/compute/docs/regions-zones" %}

<figure><img src="../../.gitbook/assets/Screen Shot 2025-01-30 at 3.20.11 PM.png" alt=""><figcaption></figcaption></figure>

....

..



